[Database]
db_host = FRCDKSPA-0002
db_name = Runtime
db_user = USE_Runtime
db_password = Run_USE_24@
odbc_driver = ODBC Driver 17 for SQL Server
table_name = History

[Tags]
# Core tags for modeling
pv_tag_name = N1N2_tt_4401
mv_tag_name = N1N2_tIC_4401_out
sp_tag_name = N1N2_tIC_4401_SP

# Optional: PID parameters if historized and to be used as features
# Use kp_hist_tag_name for clarity, matching kp_hist_lags below
# kp_hist_tag_name = N2N1_LIC_4401_Kp
# ti_hist_tag_name = N2N1_LIC_4401_Ti
# td_hist_tag_name = N2N1_LIC_4401_Td
# Optional: Measured disturbance tags (add more as disturbance_tag_2, disturbance_tag_3, etc.)
disturbance_tag_1 = N1N2_XV4422_zso ; e.g., InletFlow.PV, leave blank if not used
disturbance_tag_2 = ACOM_T_COM_XV_02_O
# disturbance_tag_3 =  N1N2_XV4422_zso


[DataPeriod]
# Period for data extraction
start_time = 2025-05-17 18:34:52
end_time = 2025-05-18 22:44:00
ww_resolution_ms = 100

[ModelFeatures]
# Number of past time steps (lags) to use for each feature.
pv_lags = 10
mv_lags = 10
sp_lags = 10

# Lags for optional features (set to 0 if tag is not used or no lags desired for it)
kp_hist_lags = 0
ti_hist_lags = 0
td_hist_lags = 0
disturbance_1_lags = 10               ; Lags for disturbance_tag_1
disturbance_2_lags = 10               ; Lags for disturbance_tag_2
# disturbance_3_lags = 10  

# Data scaling method: MinMaxScaler or StandardScaler
scaler_type = MinMaxScaler

# Data split ratios (chronological)
train_split_ratio = 0.7
validation_split_ratio = 0.15
# Test set ratio is implicitly (1.0 - train_split_ratio - validation_split_ratio)

[ModelParams]
# Hyperparameters for the machine learning model
model_type = RandomForestRegressor
n_estimators = 100
max_depth = 7
random_state = 42
min_samples_leaf = 10

[ModelOutput]
# Paths for saving the trained model, scalers, and evaluation plot
model_save_path = ./Pid_Model/trained.joblib
scalers_save_path =./Pid_Model/scalers.joblib ; Both X and Y scalers will be saved here
plot_save_path = ./trace/pid_model_pv_prediction_plot.png

[NotebookConversion]
# Mettez à true pour activer la conversion
enable_conversion = True

# Chemin COMPLET vers votre fichier notebook .ipynb source
# Exemple Windows: C:\chemin\vers\mon_notebook.ipynb
# Exemple Linux/macOS: /chemin/vers/mon_notebook.ipynb
notebook_source_path = C:\Users\EDVA10053293\OneDrive - Groupe Avril\08 - Marchine Learning\Jupyter\Regulation PID\Pid_Model_builder\pid_model_builder.ipynb

# Optionnel: Chemin COMPLET pour sauvegarder le script .py généré
# Si laissé vide ou commenté, le fichier .py sera créé dans le même
# répertoire que le notebook_source_path, avec le même nom de base.
# Exemple: python_script_output_path = C:\chemin\vers\output\script_genere.py
python_script_output_path =

[Output]
image_output_dir = ./trace
# Nouveau paramètre pour le nom de base du fichier de log
# Si vous voulez que le log s'appelle "mon_log_personnalise.txt", mettez :
log_file_base_name = ./trace/pid_model_builder_log
# Si cette ligne est absente, commentée, ou si la valeur est vide,
# le log prendra le nom du script (ex: pid_model_builder.txt si le script est pid_model_builder.py)